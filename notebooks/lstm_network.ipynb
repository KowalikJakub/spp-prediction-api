{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from keras.losses import mean_absolute_error, mean_squared_error\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_prediction_dataset(dataset, look_back=1):\n",
    "    return X[:len(X) - look_back], X[look_back:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - AAPL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'aapl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\k0wal1k\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\k0wal1k\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 4s 3ms/step - loss: 0.0925 - val_loss: 0.1131\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.1153 - val_loss: 0.0865\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.1001 - val_loss: 0.0816\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 188us/step - loss: 0.0944 - val_loss: 0.0828\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 186us/step - loss: 0.0851 - val_loss: 0.1120\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 250us/step - loss: 0.0710 - val_loss: 0.0632\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 273us/step - loss: 0.0743 - val_loss: 0.0994\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 276us/step - loss: 0.0615 - val_loss: 0.0671\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 193us/step - loss: 0.0646 - val_loss: 0.1115\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 365us/step - loss: 0.0538 - val_loss: 0.0530\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 186us/step - loss: 0.0587 - val_loss: 0.0702\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 189us/step - loss: 0.0555 - val_loss: 0.0519\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0516 - val_loss: 0.0832\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 249us/step - loss: 0.0524 - val_loss: 0.0503\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 268us/step - loss: 0.0469 - val_loss: 0.0365\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 304us/step - loss: 0.0491 - val_loss: 0.0766\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0416 - val_loss: 0.0451\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 244us/step - loss: 0.0474 - val_loss: 0.0951\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 280us/step - loss: 0.0476 - val_loss: 0.0431\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 248us/step - loss: 0.0472 - val_loss: 0.0381\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 238us/step - loss: 0.0458 - val_loss: 0.0605\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0366 - val_loss: 0.1096\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0430 - val_loss: 0.0455\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0436 - val_loss: 0.0395\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0400 - val_loss: 0.0409\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0415 - val_loss: 0.0950\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 243us/step - loss: 0.0411 - val_loss: 0.0361\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0409 - val_loss: 0.0402\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0440 - val_loss: 0.0268\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 189us/step - loss: 0.0422 - val_loss: 0.0350\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0377 - val_loss: 0.0487\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 249us/step - loss: 0.0352 - val_loss: 0.0366\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 293us/step - loss: 0.0432 - val_loss: 0.0308\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 277us/step - loss: 0.0398 - val_loss: 0.0348\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 265us/step - loss: 0.0356 - val_loss: 0.0518\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0412 - val_loss: 0.0296\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0396 - val_loss: 0.0320\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0331 - val_loss: 0.0366\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 193us/step - loss: 0.0400 - val_loss: 0.0313\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 238us/step - loss: 0.0366 - val_loss: 0.0743\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0368 - val_loss: 0.0364\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0338 - val_loss: 0.0344\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0339 - val_loss: 0.0625\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0342 - val_loss: 0.0435\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0334 - val_loss: 0.0502\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0335 - val_loss: 0.0631\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 193us/step - loss: 0.0355 - val_loss: 0.0273\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0324 - val_loss: 0.0543\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 229us/step - loss: 0.0304 - val_loss: 0.0306\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0361 - val_loss: 0.0221\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0334 - val_loss: 0.0680\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 239us/step - loss: 0.0303 - val_loss: 0.0656\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 225us/step - loss: 0.0336 - val_loss: 0.0511\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0300 - val_loss: 0.0330\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0311 - val_loss: 0.0614\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0288 - val_loss: 0.0635\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 189us/step - loss: 0.0335 - val_loss: 0.0576\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.0268 - val_loss: 0.0405\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0321 - val_loss: 0.0369\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.0268 - val_loss: 0.0645\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0303 - val_loss: 0.0711\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0305 - val_loss: 0.0594\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 193us/step - loss: 0.0265 - val_loss: 0.0437\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.0300 - val_loss: 0.0297\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 188us/step - loss: 0.0290 - val_loss: 0.0509\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 224us/step - loss: 0.0291 - val_loss: 0.0529\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0314 - val_loss: 0.0522\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0305 - val_loss: 0.0503\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 235us/step - loss: 0.0297 - val_loss: 0.0640\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 242us/step - loss: 0.0282 - val_loss: 0.0181\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0299 - val_loss: 0.0275\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 225us/step - loss: 0.0288 - val_loss: 0.0364\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0312 - val_loss: 0.0510\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0267 - val_loss: 0.0499\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 276us/step - loss: 0.0299 - val_loss: 0.0604\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 260us/step - loss: 0.0295 - val_loss: 0.0606\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 242us/step - loss: 0.0265 - val_loss: 0.0492\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 261us/step - loss: 0.0295 - val_loss: 0.0291\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 264us/step - loss: 0.0271 - val_loss: 0.0592\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0303 - val_loss: 0.0419\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.0289 - val_loss: 0.0564\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0292 - val_loss: 0.0416\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0295 - val_loss: 0.0525\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0277 - val_loss: 0.0191\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 252us/step - loss: 0.0283 - val_loss: 0.0542\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 180us/step - loss: 0.0290 - val_loss: 0.0388\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 176us/step - loss: 0.0284 - val_loss: 0.0506\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 166us/step - loss: 0.0286 - val_loss: 0.0383\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 167us/step - loss: 0.0264 - val_loss: 0.0359\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 169us/step - loss: 0.0255 - val_loss: 0.0237\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 164us/step - loss: 0.0278 - val_loss: 0.0538\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 172us/step - loss: 0.0267 - val_loss: 0.0249\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 165us/step - loss: 0.0278 - val_loss: 0.0455\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 173us/step - loss: 0.0259 - val_loss: 0.0198\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 164us/step - loss: 0.0248 - val_loss: 0.0335\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 165us/step - loss: 0.0271 - val_loss: 0.0502\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 185us/step - loss: 0.0275 - val_loss: 0.0472\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 220us/step - loss: 0.0251 - val_loss: 0.0201\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 172us/step - loss: 0.0261 - val_loss: 0.0525\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 164us/step - loss: 0.0249 - val_loss: 0.0516\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "checkpoints.remove('.ipynb_checkpoints')\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "\n",
    "model.save('../static/{0}/neural_networks/1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - AMD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'amd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 9s 8ms/step - loss: 0.0657 - val_loss: 0.1139\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 250us/step - loss: 0.1139 - val_loss: 0.2212\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0931 - val_loss: 0.1755\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 231us/step - loss: 0.0889 - val_loss: 0.1477\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 233us/step - loss: 0.0901 - val_loss: 0.0632\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 299us/step - loss: 0.0809 - val_loss: 0.1576\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 315us/step - loss: 0.0746 - val_loss: 0.1313\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 241us/step - loss: 0.0610 - val_loss: 0.1711\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 240us/step - loss: 0.0542 - val_loss: 0.0906\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 248us/step - loss: 0.0585 - val_loss: 0.0490\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0587 - val_loss: 0.1311\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 241us/step - loss: 0.0528 - val_loss: 0.1661\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 224us/step - loss: 0.0495 - val_loss: 0.0634\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 238us/step - loss: 0.0537 - val_loss: 0.0593\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 232us/step - loss: 0.0488 - val_loss: 0.0870\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0450 - val_loss: 0.0678\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0485 - val_loss: 0.0807\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0473 - val_loss: 0.0650\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 316us/step - loss: 0.0469 - val_loss: 0.0716\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 261us/step - loss: 0.0409 - val_loss: 0.1259\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 219us/step - loss: 0.0416 - val_loss: 0.1266\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 232us/step - loss: 0.0392 - val_loss: 0.1374\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 220us/step - loss: 0.0398 - val_loss: 0.1331\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 231us/step - loss: 0.0368 - val_loss: 0.1510\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0382 - val_loss: 0.0783\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 212us/step - loss: 0.0385 - val_loss: 0.0689\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0370 - val_loss: 0.1370\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 233us/step - loss: 0.0379 - val_loss: 0.0715\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0417 - val_loss: 0.0589\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 235us/step - loss: 0.0334 - val_loss: 0.1404\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0341 - val_loss: 0.1401\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 285us/step - loss: 0.0362 - val_loss: 0.0705\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 285us/step - loss: 0.0381 - val_loss: 0.0705\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0341 - val_loss: 0.0718\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0332 - val_loss: 0.1013\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 241us/step - loss: 0.0358 - val_loss: 0.0632\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0353 - val_loss: 0.1166\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 260us/step - loss: 0.0329 - val_loss: 0.0653\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 285us/step - loss: 0.0355 - val_loss: 0.1021\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 292us/step - loss: 0.0317 - val_loss: 0.0678\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 266us/step - loss: 0.0381 - val_loss: 0.0592\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 268us/step - loss: 0.0346 - val_loss: 0.0577\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 248us/step - loss: 0.0307 - val_loss: 0.0840\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0336 - val_loss: 0.0607\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0333 - val_loss: 0.0627\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 241us/step - loss: 0.0338 - val_loss: 0.0597\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0307 - val_loss: 0.0667\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0326 - val_loss: 0.0687\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0341 - val_loss: 0.0627\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0307 - val_loss: 0.0933\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0302 - val_loss: 0.0592\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0350 - val_loss: 0.0636\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 212us/step - loss: 0.0315 - val_loss: 0.0617\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0317 - val_loss: 0.0655\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0304 - val_loss: 0.0665\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0297 - val_loss: 0.0889\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0307 - val_loss: 0.0683\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0339 - val_loss: 0.0669\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0306 - val_loss: 0.0677\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0302 - val_loss: 0.0667\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0311 - val_loss: 0.0688\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0320 - val_loss: 0.0666\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0287 - val_loss: 0.0692\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0296 - val_loss: 0.0708\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0297 - val_loss: 0.0718\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0288 - val_loss: 0.0724\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0286 - val_loss: 0.0725\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 228us/step - loss: 0.0307 - val_loss: 0.0721\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0283 - val_loss: 0.0710\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0288 - val_loss: 0.0698\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0300 - val_loss: 0.0695\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0305 - val_loss: 0.0688\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0283 - val_loss: 0.0662\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 245us/step - loss: 0.0297 - val_loss: 0.0674\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0287 - val_loss: 0.0664\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0301 - val_loss: 0.0677\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 219us/step - loss: 0.0285 - val_loss: 0.0686\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 234us/step - loss: 0.0276 - val_loss: 0.0690\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0294 - val_loss: 0.0684\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 225us/step - loss: 0.0301 - val_loss: 0.0672\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0278 - val_loss: 0.0666\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0282 - val_loss: 0.0668\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0302 - val_loss: 0.0668\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 217us/step - loss: 0.0274 - val_loss: 0.0677\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0279 - val_loss: 0.0667\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0286 - val_loss: 0.0653\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0298 - val_loss: 0.0718\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 246us/step - loss: 0.0266 - val_loss: 0.0698\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0300 - val_loss: 0.0694\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 246us/step - loss: 0.0274 - val_loss: 0.0682\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0282 - val_loss: 0.0680\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 234us/step - loss: 0.0275 - val_loss: 0.0683\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 263us/step - loss: 0.0276 - val_loss: 0.0675\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 295us/step - loss: 0.0275 - val_loss: 0.0680\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 300us/step - loss: 0.0289 - val_loss: 0.0713\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 255us/step - loss: 0.0272 - val_loss: 0.0677\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 280us/step - loss: 0.0273 - val_loss: 0.0678\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 284us/step - loss: 0.0275 - val_loss: 0.0677\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 272us/step - loss: 0.0272 - val_loss: 0.0676\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 302us/step - loss: 0.0269 - val_loss: 0.0667\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "try:\n",
    "    checkpoints.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "\n",
    "try:\n",
    "    os.mkdir(r'..\\static\\{0}\\neural_networks'.format(stock_name))\n",
    "except:\n",
    "    pass\n",
    "model.save(r'..\\static\\{0}\\neural_networks\\1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - AMZN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'amzn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 6s 5ms/step - loss: 0.0764 - val_loss: 0.0604\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.1343 - val_loss: 0.1222\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.1196 - val_loss: 0.1945\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.1017 - val_loss: 0.1102\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.1093 - val_loss: 0.1195\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0863 - val_loss: 0.2069\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0756 - val_loss: 0.1831\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0726 - val_loss: 0.1860\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0696 - val_loss: 0.0376\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0699 - val_loss: 0.0312\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0653 - val_loss: 0.0319\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0570 - val_loss: 0.1230\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0559 - val_loss: 0.0353\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0518 - val_loss: 0.0346\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0502 - val_loss: 0.1273\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0522 - val_loss: 0.1346\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0531 - val_loss: 0.1183\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0490 - val_loss: 0.1384\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0458 - val_loss: 0.0450\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0514 - val_loss: 0.0326\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0436 - val_loss: 0.1181\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 234us/step - loss: 0.0481 - val_loss: 0.0424\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0468 - val_loss: 0.0552\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0489 - val_loss: 0.1086\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0469 - val_loss: 0.1287\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0494 - val_loss: 0.1002\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 257us/step - loss: 0.0452 - val_loss: 0.1220\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 278us/step - loss: 0.0412 - val_loss: 0.0381\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 245us/step - loss: 0.0448 - val_loss: 0.0845\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 245us/step - loss: 0.0443 - val_loss: 0.0375\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0449 - val_loss: 0.1165\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 247us/step - loss: 0.0393 - val_loss: 0.0343\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 231us/step - loss: 0.0438 - val_loss: 0.0851\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0428 - val_loss: 0.0343\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 250us/step - loss: 0.0393 - val_loss: 0.0896\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 275us/step - loss: 0.0391 - val_loss: 0.0333\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0410 - val_loss: 0.0623\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 179us/step - loss: 0.0412 - val_loss: 0.1219\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 271us/step - loss: 0.0423 - val_loss: 0.0912\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 230us/step - loss: 0.0423 - val_loss: 0.1158\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 247us/step - loss: 0.0364 - val_loss: 0.0800\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0395 - val_loss: 0.0440\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0406 - val_loss: 0.0378\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0405 - val_loss: 0.0611\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0420 - val_loss: 0.0602\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 189us/step - loss: 0.0387 - val_loss: 0.0403\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0420 - val_loss: 0.0593\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0400 - val_loss: 0.0632\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 188us/step - loss: 0.0384 - val_loss: 0.0516\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 189us/step - loss: 0.0385 - val_loss: 0.0733\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 177us/step - loss: 0.0432 - val_loss: 0.0987\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 178us/step - loss: 0.0341 - val_loss: 0.0838\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 182us/step - loss: 0.0415 - val_loss: 0.1155\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 177us/step - loss: 0.0390 - val_loss: 0.1105\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 183us/step - loss: 0.0386 - val_loss: 0.0585\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 174us/step - loss: 0.0395 - val_loss: 0.0273\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 180us/step - loss: 0.0398 - val_loss: 0.1035\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 190us/step - loss: 0.0353 - val_loss: 0.0302\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0403 - val_loss: 0.0610\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 228us/step - loss: 0.0415 - val_loss: 0.0935\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0364 - val_loss: 0.0381\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 182us/step - loss: 0.0387 - val_loss: 0.0243\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 176us/step - loss: 0.0391 - val_loss: 0.0615\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 186us/step - loss: 0.0375 - val_loss: 0.1010\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 185us/step - loss: 0.0356 - val_loss: 0.0526\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 178us/step - loss: 0.0384 - val_loss: 0.0514\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 186us/step - loss: 0.0364 - val_loss: 0.0335\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 177us/step - loss: 0.0374 - val_loss: 0.0550\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 185us/step - loss: 0.0340 - val_loss: 0.0754\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 183us/step - loss: 0.0361 - val_loss: 0.0317\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0375 - val_loss: 0.0517\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 224us/step - loss: 0.0399 - val_loss: 0.0976\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0306 - val_loss: 0.0891\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 187us/step - loss: 0.0365 - val_loss: 0.0644\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 181us/step - loss: 0.0403 - val_loss: 0.0918\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 185us/step - loss: 0.0342 - val_loss: 0.0326\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 175us/step - loss: 0.0346 - val_loss: 0.0335\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0364 - val_loss: 0.0266\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 277us/step - loss: 0.0333 - val_loss: 0.0472\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0387 - val_loss: 0.0951\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 186us/step - loss: 0.0322 - val_loss: 0.0618\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 181us/step - loss: 0.0358 - val_loss: 0.0464\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 227us/step - loss: 0.0339 - val_loss: 0.0674\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 236us/step - loss: 0.0315 - val_loss: 0.0277\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 283us/step - loss: 0.0362 - val_loss: 0.0500\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 233us/step - loss: 0.0368 - val_loss: 0.0885\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 234us/step - loss: 0.0315 - val_loss: 0.0749\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0350 - val_loss: 0.0306\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 235us/step - loss: 0.0345 - val_loss: 0.0288\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0346 - val_loss: 0.0447\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 262us/step - loss: 0.0321 - val_loss: 0.0408\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0364 - val_loss: 0.0843\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 249us/step - loss: 0.0304 - val_loss: 0.0441\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 272us/step - loss: 0.0337 - val_loss: 0.0268\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 269us/step - loss: 0.0340 - val_loss: 0.0416\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 262us/step - loss: 0.0356 - val_loss: 0.0880\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 295us/step - loss: 0.0305 - val_loss: 0.0699\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 308us/step - loss: 0.0345 - val_loss: 0.0904\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 311us/step - loss: 0.0326 - val_loss: 0.0752\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 308us/step - loss: 0.0310 - val_loss: 0.0537\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "try:\n",
    "    checkpoints.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "try:\n",
    "    os.mkdir(r'..\\static\\{0}\\neural_networks'.format(stock_name))\n",
    "except:\n",
    "    pass\n",
    "model.save(r'..\\static\\{0}\\neural_networks\\1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - EBAY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'ebay'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 7s 6ms/step - loss: 0.1504 - val_loss: 0.1060\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.1235 - val_loss: 0.0991\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.1004 - val_loss: 0.1160\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0968 - val_loss: 0.0633\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0749 - val_loss: 0.1042\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0794 - val_loss: 0.1021\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0663 - val_loss: 0.1101\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0672 - val_loss: 0.0979\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0609 - val_loss: 0.0862\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0585 - val_loss: 0.0832\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 244us/step - loss: 0.0552 - val_loss: 0.1093\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0604 - val_loss: 0.0369\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0513 - val_loss: 0.0467\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0539 - val_loss: 0.0840\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0527 - val_loss: 0.0579\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0493 - val_loss: 0.0693\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0491 - val_loss: 0.0696\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0482 - val_loss: 0.0482\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0474 - val_loss: 0.0683\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0432 - val_loss: 0.0359\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0451 - val_loss: 0.0573\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 212us/step - loss: 0.0458 - val_loss: 0.0481\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0460 - val_loss: 0.0155\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0413 - val_loss: 0.0595\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0428 - val_loss: 0.0587\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 237us/step - loss: 0.0424 - val_loss: 0.0290\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0422 - val_loss: 0.0458\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0410 - val_loss: 0.0434\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0422 - val_loss: 0.0534\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0395 - val_loss: 0.0552\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0405 - val_loss: 0.0247\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0383 - val_loss: 0.0499\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0408 - val_loss: 0.0252\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0399 - val_loss: 0.0082\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0377 - val_loss: 0.0513\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0387 - val_loss: 0.0189\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 237us/step - loss: 0.0378 - val_loss: 0.0290\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 277us/step - loss: 0.0394 - val_loss: 0.0236\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 246us/step - loss: 0.0362 - val_loss: 0.0345\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0384 - val_loss: 0.0423\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0370 - val_loss: 0.0184\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0360 - val_loss: 0.0366\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0383 - val_loss: 0.0432\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0377 - val_loss: 0.0383\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0364 - val_loss: 0.0349\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0371 - val_loss: 0.0347\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0375 - val_loss: 0.0297\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0351 - val_loss: 0.0075\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0366 - val_loss: 0.0493\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0374 - val_loss: 0.0304\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0372 - val_loss: 0.0068\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0361 - val_loss: 0.0426\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0368 - val_loss: 0.0076\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0359 - val_loss: 0.0422\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0365 - val_loss: 0.0073\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0346 - val_loss: 0.0437\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0344 - val_loss: 0.0399\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0352 - val_loss: 0.0184\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0348 - val_loss: 0.0351\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0332 - val_loss: 0.0192\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0340 - val_loss: 0.0430\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0326 - val_loss: 0.0187\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0317 - val_loss: 0.0358\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0337 - val_loss: 0.0165\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0299 - val_loss: 0.0485\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0297 - val_loss: 0.0199\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0334 - val_loss: 0.0169\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0321 - val_loss: 0.0152\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0284 - val_loss: 0.0116\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 217us/step - loss: 0.0332 - val_loss: 0.0152\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0333 - val_loss: 0.0163\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0316 - val_loss: 0.0162\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 237us/step - loss: 0.0335 - val_loss: 0.0436\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 267us/step - loss: 0.0292 - val_loss: 0.0283\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 272us/step - loss: 0.0309 - val_loss: 0.0056\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0317 - val_loss: 0.0388\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0289 - val_loss: 0.0174\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0333 - val_loss: 0.0139\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0323 - val_loss: 0.0111\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0295 - val_loss: 0.0108\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 217us/step - loss: 0.0309 - val_loss: 0.0144\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0313 - val_loss: 0.0095\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 220us/step - loss: 0.0315 - val_loss: 0.0145\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0273 - val_loss: 0.0100\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0284 - val_loss: 0.0110\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0304 - val_loss: 0.0129\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 233us/step - loss: 0.0293 - val_loss: 0.0130\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0318 - val_loss: 0.0261\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 220us/step - loss: 0.0287 - val_loss: 0.0113\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0268 - val_loss: 0.0158\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0291 - val_loss: 0.0433\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 232us/step - loss: 0.0283 - val_loss: 0.0080\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 264us/step - loss: 0.0280 - val_loss: 0.0121\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0307 - val_loss: 0.0067\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0282 - val_loss: 0.0125\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0263 - val_loss: 0.0306\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0296 - val_loss: 0.0055\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0284 - val_loss: 0.0125\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0285 - val_loss: 0.0099\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0266 - val_loss: 0.0134\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "try:\n",
    "    checkpoints.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "try:\n",
    "    os.mkdir(r'..\\static\\{0}\\neural_networks'.format(stock_name))\n",
    "except:\n",
    "    pass\n",
    "model.save(r'..\\static\\{0}\\neural_networks\\1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - INTC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'intc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 7s 6ms/step - loss: 0.0968 - val_loss: 0.1184\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.1060 - val_loss: 0.2037\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0845 - val_loss: 0.1349\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0815 - val_loss: 0.1471\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0789 - val_loss: 0.1766\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0689 - val_loss: 0.1328\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0603 - val_loss: 0.0620\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0602 - val_loss: 0.0543\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0545 - val_loss: 0.0546\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0513 - val_loss: 0.0548\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0510 - val_loss: 0.0545\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0477 - val_loss: 0.1017\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0452 - val_loss: 0.0645\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0473 - val_loss: 0.0603\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0423 - val_loss: 0.0650\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0444 - val_loss: 0.0635\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0383 - val_loss: 0.0621\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0409 - val_loss: 0.0598\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0397 - val_loss: 0.0829\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0376 - val_loss: 0.0626\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0381 - val_loss: 0.1069\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0344 - val_loss: 0.0941\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0356 - val_loss: 0.1014\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0359 - val_loss: 0.0654\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0326 - val_loss: 0.1012\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0392 - val_loss: 0.1172\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0333 - val_loss: 0.0655\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0345 - val_loss: 0.0575\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0347 - val_loss: 0.0852\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0310 - val_loss: 0.1190\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0312 - val_loss: 0.0653\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0329 - val_loss: 0.0964\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0303 - val_loss: 0.1175\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0313 - val_loss: 0.1140\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 217us/step - loss: 0.0303 - val_loss: 0.1304\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0330 - val_loss: 0.1046\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0324 - val_loss: 0.1058\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0285 - val_loss: 0.1064\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 195us/step - loss: 0.0318 - val_loss: 0.0640\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0314 - val_loss: 0.0957\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0273 - val_loss: 0.1120\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0317 - val_loss: 0.1017\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 191us/step - loss: 0.0307 - val_loss: 0.0605\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0311 - val_loss: 0.0909\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0294 - val_loss: 0.0573\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0302 - val_loss: 0.0524\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0305 - val_loss: 0.1048\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0301 - val_loss: 0.1117\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0279 - val_loss: 0.1130\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0286 - val_loss: 0.0969\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0284 - val_loss: 0.0598\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0289 - val_loss: 0.0526\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0278 - val_loss: 0.0877\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0315 - val_loss: 0.1041\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0295 - val_loss: 0.0966\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0252 - val_loss: 0.0939\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 219us/step - loss: 0.0289 - val_loss: 0.0557\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0274 - val_loss: 0.0473\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0281 - val_loss: 0.0871\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0257 - val_loss: 0.0929\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0269 - val_loss: 0.0897\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0259 - val_loss: 0.1038\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0265 - val_loss: 0.0515\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0307 - val_loss: 0.0945\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0250 - val_loss: 0.0962\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0255 - val_loss: 0.0880\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0247 - val_loss: 0.1030\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0260 - val_loss: 0.0874\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0236 - val_loss: 0.0953\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0254 - val_loss: 0.0885\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0271 - val_loss: 0.0895\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0255 - val_loss: 0.0787\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0245 - val_loss: 0.0906\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0276 - val_loss: 0.0801\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0217 - val_loss: 0.0885\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0244 - val_loss: 0.0968\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 232us/step - loss: 0.0245 - val_loss: 0.0864\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0229 - val_loss: 0.0903\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0221 - val_loss: 0.0465\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0246 - val_loss: 0.0851\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0223 - val_loss: 0.0435\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0275 - val_loss: 0.0741\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0220 - val_loss: 0.0771\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0236 - val_loss: 0.0842\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0223 - val_loss: 0.0840\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0222 - val_loss: 0.0822\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0229 - val_loss: 0.0858\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 290us/step - loss: 0.0232 - val_loss: 0.0830\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 247us/step - loss: 0.0234 - val_loss: 0.0843\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0215 - val_loss: 0.0853\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0239 - val_loss: 0.0796\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 223us/step - loss: 0.0223 - val_loss: 0.0826\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0225 - val_loss: 0.0836\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0231 - val_loss: 0.0818\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0218 - val_loss: 0.0827\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 206us/step - loss: 0.0231 - val_loss: 0.0837\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0216 - val_loss: 0.0862\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0228 - val_loss: 0.0807\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0233 - val_loss: 0.0797\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0218 - val_loss: 0.0849\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "try:\n",
    "    checkpoints.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "try:\n",
    "    os.mkdir(r'..\\static\\{0}\\neural_networks'.format(stock_name))\n",
    "except:\n",
    "    pass\n",
    "model.save(r'..\\static\\{0}\\neural_networks\\1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training - MSFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_name = 'msft'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1132 samples, validate on 126 samples\n",
      "Epoch 1/100\n",
      "1132/1132 [==============================] - 7s 6ms/step - loss: 0.0666 - val_loss: 0.0923\n",
      "Epoch 2/100\n",
      "1132/1132 [==============================] - 0s 256us/step - loss: 0.1153 - val_loss: 0.1834\n",
      "Epoch 3/100\n",
      "1132/1132 [==============================] - 0s 341us/step - loss: 0.0988 - val_loss: 0.1337\n",
      "Epoch 4/100\n",
      "1132/1132 [==============================] - 0s 266us/step - loss: 0.0960 - val_loss: 0.0646\n",
      "Epoch 5/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0967 - val_loss: 0.0647\n",
      "Epoch 6/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0781 - val_loss: 0.2001\n",
      "Epoch 7/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0647 - val_loss: 0.1874\n",
      "Epoch 8/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0616 - val_loss: 0.1519\n",
      "Epoch 9/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0560 - val_loss: 0.2127\n",
      "Epoch 10/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0534 - val_loss: 0.1545\n",
      "Epoch 11/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0538 - val_loss: 0.0606\n",
      "Epoch 12/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0517 - val_loss: 0.1617\n",
      "Epoch 13/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0488 - val_loss: 0.0630\n",
      "Epoch 14/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0477 - val_loss: 0.0784\n",
      "Epoch 15/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0477 - val_loss: 0.0824\n",
      "Epoch 16/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0455 - val_loss: 0.0814\n",
      "Epoch 17/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0458 - val_loss: 0.1163\n",
      "Epoch 18/100\n",
      "1132/1132 [==============================] - 0s 194us/step - loss: 0.0465 - val_loss: 0.0707\n",
      "Epoch 19/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0454 - val_loss: 0.0693\n",
      "Epoch 20/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0433 - val_loss: 0.1576\n",
      "Epoch 21/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0395 - val_loss: 0.1289\n",
      "Epoch 22/100\n",
      "1132/1132 [==============================] - 0s 220us/step - loss: 0.0387 - val_loss: 0.0685\n",
      "Epoch 23/100\n",
      "1132/1132 [==============================] - 0s 246us/step - loss: 0.0389 - val_loss: 0.0740\n",
      "Epoch 24/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0419 - val_loss: 0.0622\n",
      "Epoch 25/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0378 - val_loss: 0.0610\n",
      "Epoch 26/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0373 - val_loss: 0.0642\n",
      "Epoch 27/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0427 - val_loss: 0.0581\n",
      "Epoch 28/100\n",
      "1132/1132 [==============================] - 0s 202us/step - loss: 0.0390 - val_loss: 0.0683\n",
      "Epoch 29/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0378 - val_loss: 0.0582\n",
      "Epoch 30/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0402 - val_loss: 0.1272\n",
      "Epoch 31/100\n",
      "1132/1132 [==============================] - 0s 212us/step - loss: 0.0338 - val_loss: 0.1019\n",
      "Epoch 32/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0350 - val_loss: 0.1127\n",
      "Epoch 33/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0366 - val_loss: 0.0629\n",
      "Epoch 34/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0378 - val_loss: 0.1302\n",
      "Epoch 35/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0348 - val_loss: 0.0601\n",
      "Epoch 36/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0375 - val_loss: 0.0655\n",
      "Epoch 37/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0324 - val_loss: 0.1093\n",
      "Epoch 38/100\n",
      "1132/1132 [==============================] - 0s 203us/step - loss: 0.0350 - val_loss: 0.0599\n",
      "Epoch 39/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0405 - val_loss: 0.0551\n",
      "Epoch 40/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0334 - val_loss: 0.1258\n",
      "Epoch 41/100\n",
      "1132/1132 [==============================] - 0s 193us/step - loss: 0.0327 - val_loss: 0.0613\n",
      "Epoch 42/100\n",
      "1132/1132 [==============================] - 0s 197us/step - loss: 0.0382 - val_loss: 0.0686\n",
      "Epoch 43/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0304 - val_loss: 0.0552\n",
      "Epoch 44/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0359 - val_loss: 0.0544\n",
      "Epoch 45/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0328 - val_loss: 0.1212\n",
      "Epoch 46/100\n",
      "1132/1132 [==============================] - 0s 198us/step - loss: 0.0329 - val_loss: 0.1257\n",
      "Epoch 47/100\n",
      "1132/1132 [==============================] - 0s 196us/step - loss: 0.0332 - val_loss: 0.0641\n",
      "Epoch 48/100\n",
      "1132/1132 [==============================] - 0s 199us/step - loss: 0.0317 - val_loss: 0.1088\n",
      "Epoch 49/100\n",
      "1132/1132 [==============================] - 0s 200us/step - loss: 0.0319 - val_loss: 0.0675\n",
      "Epoch 50/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0314 - val_loss: 0.0887\n",
      "Epoch 51/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0305 - val_loss: 0.0643\n",
      "Epoch 52/100\n",
      "1132/1132 [==============================] - 0s 224us/step - loss: 0.0307 - val_loss: 0.0993\n",
      "Epoch 53/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0323 - val_loss: 0.0655\n",
      "Epoch 54/100\n",
      "1132/1132 [==============================] - 0s 226us/step - loss: 0.0343 - val_loss: 0.0627\n",
      "Epoch 55/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0307 - val_loss: 0.0667\n",
      "Epoch 56/100\n",
      "1132/1132 [==============================] - 0s 208us/step - loss: 0.0302 - val_loss: 0.0885\n",
      "Epoch 57/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0316 - val_loss: 0.0667\n",
      "Epoch 58/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0315 - val_loss: 0.0651\n",
      "Epoch 59/100\n",
      "1132/1132 [==============================] - 0s 219us/step - loss: 0.0297 - val_loss: 0.0661\n",
      "Epoch 60/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0298 - val_loss: 0.0871\n",
      "Epoch 61/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0301 - val_loss: 0.0726\n",
      "Epoch 62/100\n",
      "1132/1132 [==============================] - 0s 207us/step - loss: 0.0295 - val_loss: 0.0735\n",
      "Epoch 63/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0296 - val_loss: 0.0753\n",
      "Epoch 64/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0287 - val_loss: 0.0742\n",
      "Epoch 65/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0289 - val_loss: 0.0721\n",
      "Epoch 66/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0296 - val_loss: 0.0737\n",
      "Epoch 67/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0285 - val_loss: 0.0749\n",
      "Epoch 68/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0286 - val_loss: 0.0725\n",
      "Epoch 69/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0296 - val_loss: 0.0700\n",
      "Epoch 70/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0290 - val_loss: 0.0716\n",
      "Epoch 71/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0280 - val_loss: 0.0728\n",
      "Epoch 72/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0282 - val_loss: 0.0736\n",
      "Epoch 73/100\n",
      "1132/1132 [==============================] - 0s 214us/step - loss: 0.0288 - val_loss: 0.0719\n",
      "Epoch 74/100\n",
      "1132/1132 [==============================] - 0s 229us/step - loss: 0.0297 - val_loss: 0.0772\n",
      "Epoch 75/100\n",
      "1132/1132 [==============================] - 0s 205us/step - loss: 0.0270 - val_loss: 0.0728\n",
      "Epoch 76/100\n",
      "1132/1132 [==============================] - 0s 201us/step - loss: 0.0307 - val_loss: 0.0745\n",
      "Epoch 77/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0283 - val_loss: 0.0715\n",
      "Epoch 78/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0293 - val_loss: 0.0732\n",
      "Epoch 79/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0278 - val_loss: 0.0713\n",
      "Epoch 80/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0283 - val_loss: 0.0716\n",
      "Epoch 81/100\n",
      "1132/1132 [==============================] - 0s 232us/step - loss: 0.0282 - val_loss: 0.0712\n",
      "Epoch 82/100\n",
      "1132/1132 [==============================] - 0s 222us/step - loss: 0.0283 - val_loss: 0.0709\n",
      "Epoch 83/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0294 - val_loss: 0.0696\n",
      "Epoch 84/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0271 - val_loss: 0.0699\n",
      "Epoch 85/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0277 - val_loss: 0.0709\n",
      "Epoch 86/100\n",
      "1132/1132 [==============================] - 0s 213us/step - loss: 0.0280 - val_loss: 0.0700\n",
      "Epoch 87/100\n",
      "1132/1132 [==============================] - 0s 219us/step - loss: 0.0278 - val_loss: 0.0701\n",
      "Epoch 88/100\n",
      "1132/1132 [==============================] - 0s 209us/step - loss: 0.0283 - val_loss: 0.0701\n",
      "Epoch 89/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0270 - val_loss: 0.0701\n",
      "Epoch 90/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0270 - val_loss: 0.0694\n",
      "Epoch 91/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0279 - val_loss: 0.0690\n",
      "Epoch 92/100\n",
      "1132/1132 [==============================] - 0s 215us/step - loss: 0.0276 - val_loss: 0.0681\n",
      "Epoch 93/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0275 - val_loss: 0.0675\n",
      "Epoch 94/100\n",
      "1132/1132 [==============================] - 0s 204us/step - loss: 0.0269 - val_loss: 0.0682\n",
      "Epoch 95/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0275 - val_loss: 0.0680\n",
      "Epoch 96/100\n",
      "1132/1132 [==============================] - 0s 216us/step - loss: 0.0278 - val_loss: 0.0682\n",
      "Epoch 97/100\n",
      "1132/1132 [==============================] - 0s 210us/step - loss: 0.0279 - val_loss: 0.0680\n",
      "Epoch 98/100\n",
      "1132/1132 [==============================] - 0s 211us/step - loss: 0.0271 - val_loss: 0.0676\n",
      "Epoch 99/100\n",
      "1132/1132 [==============================] - 0s 218us/step - loss: 0.0277 - val_loss: 0.0676\n",
      "Epoch 100/100\n",
      "1132/1132 [==============================] - 0s 221us/step - loss: 0.0283 - val_loss: 0.0674\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(r'data/{0}.csv'.format(stock_name))\n",
    "\n",
    "look_back = 1\n",
    "X = data.filterred.values\n",
    "\n",
    "x, y = create_prediction_dataset(X, look_back=look_back)\n",
    "\n",
    "x_train, y_train = x, y\n",
    "\n",
    "x_train = np.reshape(x_train, (x_train.shape[0], look_back, 1))\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(units=64, return_sequences=True,input_shape=(1, look_back)))\n",
    "model.add(LSTM(units=128,return_sequences=True))\n",
    "model.add(LSTM(units=32))\n",
    "model.add(Dense(units=1))\n",
    "\n",
    "optimizer = RMSprop(lr=10e-3)\n",
    "model.compile(loss=mean_absolute_error,\n",
    "              optimizer=optimizer)\n",
    "\n",
    "checkpoint_path = 'model_checkpoints/' + stock_name + '/'\n",
    "try:\n",
    "    os.mkdir(checkpoint_path)\n",
    "except OSError:\n",
    "    pass\n",
    "filepath = checkpoint_path + '{epoch:02d}-{val_loss:.4f}.hdf5'\n",
    "checkpointer = ModelCheckpoint(filepath, \n",
    "                               monitor='val_loss',\n",
    "                               mode='min', \n",
    "                               save_best_only=True)\n",
    "\n",
    "model.fit(x_train, \n",
    "          y_train, \n",
    "          epochs=100,\n",
    "          validation_split=0.1,\n",
    "          shuffle=False, \n",
    "          callbacks=[checkpointer])\n",
    "\n",
    "checkpoints = os.listdir(checkpoint_path)\n",
    "try:\n",
    "    checkpoints.remove('.ipynb_checkpoints')\n",
    "except:\n",
    "    pass\n",
    "sorted_checkpoints = sorted(checkpoints, key=lambda f: re.findall(r'^\\d{2}-(\\d.\\d*).hdf5', f)[0])\n",
    "minloss = sorted_checkpoints[0] \n",
    "\n",
    "model.load_weights(checkpoint_path + minloss)\n",
    "try:\n",
    "    os.mkdir(r'..\\static\\{0}\\neural_networks'.format(stock_name))\n",
    "except:\n",
    "    pass\n",
    "model.save(r'..\\static\\{0}\\neural_networks\\1.h5'.format(stock_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
